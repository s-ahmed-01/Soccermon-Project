{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from math import radians, sin, cos, sqrt, atan2\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AthleteDailyActivity\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load parquet files\n",
    "data_dir = \"Parquets/2020/2020-06\"\n",
    "df = spark.read.parquet(f\"{data_dir}/*.parquet\")\n",
    "\n",
    "# Define a UDF (User-Defined Function) to calculate distance using the Haversine formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371e3  # Radius of Earth in meters\n",
    "    phi1 = radians(lat1)\n",
    "    phi2 = radians(lat2)\n",
    "    delta_phi = radians(lat2 - lat1)\n",
    "    delta_lambda = radians(lon2 - lon1)\n",
    "    \n",
    "    a = sin(delta_phi / 2) ** 2 + cos(phi1) * cos(phi2) * sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Register the haversine function as a UDF\n",
    "from pyspark.sql.types import DoubleType\n",
    "spark.udf.register(\"haversine\", haversine, DoubleType())\n",
    "\n",
    "# Calculate total gyro change, total acceleration change, and distance between successive points\n",
    "df = df.withColumn('accel_change', F.sqrt(F.pow(F.col('accl_x'), 2) + F.pow(F.col('accl_y'), 2) + F.pow(F.col('accl_z'), 2))) \\\n",
    "       .withColumn('gyro_change', F.sqrt(F.pow(F.col('gyro_x'), 2) + F.pow(F.col('gyro_y'), 2) + F.pow(F.col('gyro_z'), 2)))\n",
    "\n",
    "# Shift the lat/lon columns by one row to calculate the distance\n",
    "window = Window.partitionBy(\"player_name\").orderBy(\"time\")\n",
    "df = df.withColumn(\"lat_shifted\", F.lag(df[\"lat\"]).over(window)) \\\n",
    "       .withColumn(\"lon_shifted\", F.lag(df[\"lon\"]).over(window))\n",
    "\n",
    "# Calculate distance using Haversine formula\n",
    "df = df.withColumn(\"distance\", F.expr(\"haversine(lat, lon, lat_shifted, lon_shifted)\"))\n",
    "\n",
    "# Group by player and date (assuming 'time' column includes date and time)\n",
    "df = df.withColumn('date', F.to_date(F.col('time')))\n",
    "\n",
    "# Aggregate the metrics for each player on each day\n",
    "df_daily = df.groupBy(\"player_name\", \"date\") \\\n",
    "    .agg(\n",
    "        F.sum(\"gyro_change\").alias(\"total_gyro_change\"),\n",
    "        F.sum(\"accel_change\").alias(\"total_accel_change\"),\n",
    "        F.sum(\"distance\").alias(\"total_distance_covered\"),\n",
    "        F.avg(\"heart_rate\").alias(\"avg_heart_rate\")\n",
    "    )\n",
    "\n",
    "# Show the final daily activity summary for each player\n",
    "df_daily.show()\n",
    "\n",
    "# Stop the Spark session\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
